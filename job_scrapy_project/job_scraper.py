import threading, os, time, random
from config import Config
from utils.logger import log
from models.boss_scraper import BossScraper
from models.proxy_scraper import ProxyScraper
from models.geek import Geek

class JobScraper:

    def __init__(self, config):
        self.config = config
        self.scrapers = {
            'boss': ProxyScraper(BossScraper(config))
        }

    def scrape_and_message(self):
        threads = []
        for job_id in self.config.jobs_id:
            for site in self.scrapers:
                scraper = self.scrapers[site]
                thread = threading.Thread(target=self.scrape_for_job, args=(scraper, job_id))
                threads.append(thread)
                thread.start()

        for thread in threads:
            thread.join()

    def format_index_total(self, index, total):
        return "{}/{}".format(index, total)

    def scrape_for_job(self, scraper, job_id):
        log(f"ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰å¼€å§‹æŠ“å–ç®€å†ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
        job = scraper.get_job_description(job_id)
        if not job:
            log(f"âŒâŒâŒâŒâŒâŒæœªè·å¾—èŒä½æè¿°ä¿¡æ¯ï¼Œç¨‹åºåœæ­¢~è¯·æ£€æµ‹ç™»å½•æ˜¯å¦è¿‡æœŸã€‚", level='error')
            return
        
        candidates = scraper.get_recommended_candidates(job_id)
        filtered_candidates = scraper.filter_candidates(job, candidates)
        candidates_total = len(filtered_candidates)
        log(f'-------- å·²åˆæ­¥ç­›é€‰å‡º [{candidates_total}] ä»½ç®€å† -------- ')
        for index, candidate in enumerate(filtered_candidates, start=1):
            # é˜²æ­¢è¢«å°
            log(f"-----è·å–ç‰›äººç®€å†è¯¦æƒ…ï¼šå¼€å§‹æŠ“å– [{candidate['geekCard']['geekName'] if candidate['geekCard'] and 'geekName' in candidate['geekCard'] else candidate['geekCard']['name']} {self.format_index_total(index, candidates_total)}] çš„ç®€å†....")
            sleep_time = random.randint(10, 40)
            log(f'é˜²æ­¢è¢«å°ç­‰å¾…éšæœºï¼š[ {sleep_time} ] ç§’...')
            time.sleep(sleep_time)
            geek = scraper.get_candidate_details(candidate)
            if scraper.compare_with_job(job, geek):
                scraper.greet_candidate(geek)

def main():
    # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
    log(f"ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ç¨‹åºå¯åŠ¨ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.abspath(os.path.join(current_dir, '..', 'config.ini'))
    config = Config(filepath=config_path)
    if not config or not config.jobs_id or len(config.jobs_id)<=0:
        log(f"âŒâŒâŒâŒâŒâŒæœªé…ç½®å¾…æ‹›è˜èŒä½ï¼Œç¨‹åºåœæ­¢~è¯·æ£€æŸ¥æ ¹ç›®å½•çš„ .ini é…ç½®æ–‡ä»¶ã€‚", level='error')
        return
    log(f"ğŸ‹ğŸ‹ğŸ‹ğŸ‹ğŸ‹ğŸ‹è§£æ .ini é…ç½®å®Œæˆ")
    scraper = JobScraper(config)
    scraper.scrape_and_message()

if __name__ == "__main__":
    main()
