import threading, os, time, random
from config import Config
from models.boss_scraper import BossScraper
from models.proxy_scraper import ProxyScraper
from models.geek import Geek

class JobScraper:

    def __init__(self, config):
        self.config = config
        self.scrapers = {
            'boss': ProxyScraper(BossScraper(config))
        }

    def scrape_and_message(self):
        threads = []
        for job_id in self.config.jobs_id:
            for site in self.scrapers:
                scraper = self.scrapers[site]
                thread = threading.Thread(target=self.scrape_for_job, args=(scraper, job_id))
                threads.append(thread)
                thread.start()

        for thread in threads:
            thread.join()

    def scrape_for_job(self, scraper, job_id):
        print(f"ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰å¼€å§‹æŠ“å–ç®€å†ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
        job = scraper.get_job_description(job_id)
        if not job:
            print(f"âŒâŒâŒâŒâŒâŒæœªè·å¾—èŒä½æè¿°ä¿¡æ¯ï¼Œç¨‹åºåœæ­¢~è¯·æ£€æµ‹ç™»å½•æ˜¯å¦è¿‡æœŸã€‚")
            return
        print('------------èŒä½æè¿°--------------')
        print(job.generate_job_desc())
        print('------------èŒä½æè¿°--------------')
        candidates = scraper.get_recommended_candidates(job_id)
        filtered_candidates = scraper.filter_candidates(job, candidates)
        print(f'-------- å·²åˆæ­¥ç­›é€‰å‡º [{len(filtered_candidates)}] ä»½ç®€å† -------- ')
        for candidate in filtered_candidates:
            # é˜²æ­¢è¢«å°
            print(f"-----è·å–ç‰›äººç®€å†è¯¦æƒ…ï¼šå¼€å§‹æŠ“å– [{candidate['geekCard']['geekName']}] çš„ç®€å†....")
            time.sleep(random.randint(10, 40))
            geek = scraper.get_candidate_details(candidate)
            if scraper.compare_with_job(job, geek):
                scraper.greet_candidate(geek)

def main():
    # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
    print(f"ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ç¨‹åºå¯åŠ¨ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")

    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.abspath(os.path.join(current_dir, '..', 'config.ini'))
    config = Config(filepath=config_path)
    if not config or not config.jobs_id or len(config.jobs_id)<=0:
        print(f"âŒâŒâŒâŒâŒâŒæœªé…ç½®å¾…æ‹›è˜èŒä½ï¼Œç¨‹åºåœæ­¢~è¯·æ£€æŸ¥æ ¹ç›®å½•çš„ .ini é…ç½®æ–‡ä»¶ã€‚")
        return
    print(f"ğŸ‹ğŸ‹ğŸ‹ğŸ‹ğŸ‹ğŸ‹è§£æ .ini é…ç½®å®Œæˆ")
    scraper = JobScraper(config)
    scraper.scrape_and_message()

if __name__ == "__main__":
    main()
